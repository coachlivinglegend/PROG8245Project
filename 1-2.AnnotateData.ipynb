{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotating the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides information on the sentiment annotation process using the `twitter-roberta-base-sentiment model` from Hugging Face. This process is crucial for labeling the data sentiment, preparing it for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Content</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Analytics</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Emojis</th>\n",
       "      <th>Profile Image</th>\n",
       "      <th>Tweet Link</th>\n",
       "      <th>Tweet ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Binance</td>\n",
       "      <td>@binance</td>\n",
       "      <td>2024-04-03T00:00:06.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>The #Binance towel comes everywhere with me......</td>\n",
       "      <td>2.2K</td>\n",
       "      <td>589</td>\n",
       "      <td>2.1K</td>\n",
       "      <td>240K</td>\n",
       "      <td>['#Binance']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['\\\\U0001f373']</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/174428939...</td>\n",
       "      <td>https://twitter.com/binance/status/17753122840...</td>\n",
       "      <td>tweet_id:1775312284052554156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ash Crypto</td>\n",
       "      <td>@Ashcryptoreal</td>\n",
       "      <td>2024-04-04T00:24:48.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>Drop your $SOL address below and\\nmake sure yo...</td>\n",
       "      <td>2.2K</td>\n",
       "      <td>518</td>\n",
       "      <td>1.4K</td>\n",
       "      <td>104K</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['\\\\U0001f447\\\\U0001f3fc']</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/169999220...</td>\n",
       "      <td>https://twitter.com/Ashcryptoreal/status/17756...</td>\n",
       "      <td>tweet_id:1775680884982616105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>@Bitcoin</td>\n",
       "      <td>2024-04-03T03:19:33.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>£52,356.70</td>\n",
       "      <td>156</td>\n",
       "      <td>141</td>\n",
       "      <td>767</td>\n",
       "      <td>161K</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/421692600...</td>\n",
       "      <td>https://twitter.com/Bitcoin/status/17753624737...</td>\n",
       "      <td>tweet_id:1775362473790447725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name          Handle                 Timestamp  Verified  \\\n",
       "0     Binance        @binance  2024-04-03T00:00:06.000Z      True   \n",
       "1  Ash Crypto  @Ashcryptoreal  2024-04-04T00:24:48.000Z      True   \n",
       "2     Bitcoin        @Bitcoin  2024-04-03T03:19:33.000Z      True   \n",
       "\n",
       "                                             Content Comments Retweets Likes  \\\n",
       "0  The #Binance towel comes everywhere with me......     2.2K      589  2.1K   \n",
       "1  Drop your $SOL address below and\\nmake sure yo...     2.2K      518  1.4K   \n",
       "2                                         £52,356.70      156      141   767   \n",
       "\n",
       "  Analytics          Tags Mentions                      Emojis  \\\n",
       "0      240K  ['#Binance']       []             ['\\\\U0001f373']   \n",
       "1      104K            []       []  ['\\\\U0001f447\\\\U0001f3fc']   \n",
       "2      161K            []       []                          []   \n",
       "\n",
       "                                       Profile Image  \\\n",
       "0  https://pbs.twimg.com/profile_images/174428939...   \n",
       "1  https://pbs.twimg.com/profile_images/169999220...   \n",
       "2  https://pbs.twimg.com/profile_images/421692600...   \n",
       "\n",
       "                                          Tweet Link  \\\n",
       "0  https://twitter.com/binance/status/17753122840...   \n",
       "1  https://twitter.com/Ashcryptoreal/status/17756...   \n",
       "2  https://twitter.com/Bitcoin/status/17753624737...   \n",
       "\n",
       "                       Tweet ID  \n",
       "0  tweet_id:1775312284052554156  \n",
       "1  tweet_id:1775680884982616105  \n",
       "2  tweet_id:1775362473790447725  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load our data from a CSV file, handling UTF-8 encoding issues\n",
    "df = pd.read_csv(\"./data/1000texts.csv\", encoding='utf-8-sig')\n",
    "\n",
    "# Display the first three rows of the dataframe to inspect the data\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the dataset, ensuring that UTF-8 encoding is used to handle any special characters in the text. \n",
    "\n",
    "The initial peek at the data with `df.head(3)` helps to confirm the structure and data types we are working with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert the 'Content' column into a list of sentences\n",
    "sentences = df['Content'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we clean the data by removing rows with missing values to maintain the quality and consistency of our dataset. \n",
    "\n",
    "We extract the tweet content into a list to facilitate the subsequent batch processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our annotation, we will be using [`twitter-roberta-base-sentiment`](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment) model on huggingface.\n",
    "\n",
    "This model is a RoBERTa-based neural network trained on approximately 58 million tweets and fine-tuned for sentiment analysis, making it highly adept at understanding the nuances of language used in tweets.\n",
    "\n",
    "**Labels Explained**\n",
    "- 0: Negative\n",
    "- 1: Neutral\n",
    "- 2: Positive\n",
    "\n",
    "These labels correspond to the sentiment expressed in each tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The api requires us to group the sentences in 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group sentences into sub-lists of 10 for batch processing\n",
    "grouped_list = [sentences[n:n+10] for n in range(0, len(sentences), 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up API for Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API token and endpoint for the annotation Hugging Face's model\n",
    "API_TOKEN = \"###\"  # actual API token goes here\n",
    "API_URL = \"https://api-inference.huggingface.co/models/cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}  # Authorization header for the API request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We configure the API with the required endpoint and authentication details. We use the API_TOKEN gotten from Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group sentences into sub-lists of 10 for batch processing\n",
    "grouped_list = [sentences[n:n+10] for n in range(0, len(sentences), 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets are grouped in batches of ten to optimize the API calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to send data to the sentiment analysis API and get the response\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store outputs\n",
    "output = []\n",
    "\n",
    "# Loop through each group of sentences and perform sentiment analysis\n",
    "for i in range(len(grouped_list)):\n",
    "    output.append(query(grouped_list[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to send each batch to the API and store the responses. Each response includes sentiment scores and labels for the batch of tweets processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43moutput\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "output[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from the API provides a score for each sentiment category per tweet, indicating the confidence level of each sentiment prediction. This allows us to determine the most likely sentiment expressed in each tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Extraction and Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the highest sentiment labels\n",
    "highest_labels = []\n",
    "\n",
    "# Extract the highest sentiment label from each result\n",
    "for group in output:\n",
    "    for result in group:\n",
    "        highest = max(result, key=lambda x: x['score'])\n",
    "        highest_labels.append(highest['label'].split('_')[1])\n",
    "\n",
    "# Add the highest sentiment labels back to the dataframe\n",
    "df['label'] = highest_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After processing, we extract the highest scoring label for each tweet and add this label back into our DataFrame. This step converts the raw output into a practical annotation of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the final dataframe to be saved\n",
    "df_final = df[['Content', 'label']]\n",
    "\n",
    "# Define the file path for the new CSV\n",
    "file_path = os.path.join('data', 'labeled_texts_1000.csv')\n",
    "\n",
    "# Save the dataframe to a CSV file, without the index, and handle UTF-8 encoding\n",
    "df_final.to_csv(file_path, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fully annotated dataset is saved as a CSV file, preserving the original text alongside the newly assigned sentiment labels. This file can now be used for further analysis and training predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Barbieri, F., Camacho-Collados, J., Espinosa Anke, L., & Neves, L. (2020). TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification. In Findings of the Association for Computational Linguistics: EMNLP 2020 (pp. 1644–1650). Association for Computational Linguistics.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf4gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
